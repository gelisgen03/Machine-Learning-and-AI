{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af765905",
   "metadata": {},
   "source": [
    "## Yedihilal Introduction to Machine Learning Summer School 2023\n",
    "\n",
    "# Assignment 2\n",
    "#### Due date: 23.59 Sunday, August 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a90110f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T06:33:46.942217Z",
     "iopub.status.busy": "2023-05-14T06:33:46.941277Z",
     "iopub.status.idle": "2023-05-14T06:33:48.415180Z",
     "shell.execute_reply": "2023-05-14T06:33:48.413954Z"
    },
    "papermill": {
     "duration": 1.484057,
     "end_time": "2023-05-14T06:33:48.418278",
     "exception": false,
     "start_time": "2023-05-14T06:33:46.934221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Name:Suleyman Asim\n",
    "# Surname:Gelisgen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156be8fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T06:33:48.450783Z",
     "iopub.status.busy": "2023-05-14T06:33:48.450365Z",
     "iopub.status.idle": "2023-05-14T06:33:48.494540Z",
     "shell.execute_reply": "2023-05-14T06:33:48.493409Z"
    },
    "papermill": {
     "duration": 0.053593,
     "end_time": "2023-05-14T06:33:48.497391",
     "exception": false,
     "start_time": "2023-05-14T06:33:48.443798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This cell generates data used in Part 1 and 2. Please do not change here.\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "def polynomial(values, coeffs):\n",
    "    # Coeffs are assumed to be in order 0, 1, ..., n-1\n",
    "    expanded = np.column_stack([coeffs[i] * (values ** i) for i in range(0, len(coeffs))])\n",
    "    return np.sum(expanded, axis=-1)\n",
    "\n",
    "def polynomial_data(coeffs, n_data=100, x_range=[-1, 1], eps=0.1):\n",
    "    x = np.random.uniform(x_range[0], x_range[1], n_data)\n",
    "    poly = polynomial(x, coeffs)\n",
    "    return x.reshape([-1, 1]), np.reshape(poly + eps * np.random.randn(n_data), [-1, 1])\n",
    "\n",
    "\n",
    "# 1 + 0.5 * x - 0.5 x^2 - 0.2 x^3 - 0.W1 x^4\n",
    "coeffs = [1, 0.5, -0.5, -0.2, -0.1]\n",
    "X, y = polynomial_data(coeffs, 100, [90, 110], 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148fcabe",
   "metadata": {},
   "source": [
    "## Part 1: Linear Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5677e098",
   "metadata": {
    "papermill": {
     "duration": 0.005519,
     "end_time": "2023-05-14T06:33:49.706771",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.701252",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Splitting\n",
    "\n",
    "Split data into training and test datasets with the test ratio of 33% and random_state=0 using Scikit-learn library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d0dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0) #egitim ve test olarak ikiye ayırdık  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b9e6e1",
   "metadata": {
    "papermill": {
     "duration": 0.006615,
     "end_time": "2023-05-14T06:33:49.743474",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.736859",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Preprocessing: Scaling\n",
    "\n",
    "Transform the data to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e6ad85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T06:33:49.758500Z",
     "iopub.status.busy": "2023-05-14T06:33:49.758062Z",
     "iopub.status.idle": "2023-05-14T06:33:49.764419Z",
     "shell.execute_reply": "2023-05-14T06:33:49.762969Z"
    },
    "papermill": {
     "duration": 0.017236,
     "end_time": "2023-05-14T06:33:49.766887",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.749651",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler() #olceklendirme (0 ort ve birim varyns)\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86061e6",
   "metadata": {
    "papermill": {
     "duration": 0.005587,
     "end_time": "2023-05-14T06:33:49.778384",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.772797",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Linear Regression Model Implementation with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f95968",
   "metadata": {
    "papermill": {
     "duration": 0.006342,
     "end_time": "2023-05-14T06:33:49.790614",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.784272",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The model function for linear regression, which is a function that maps from `x` to `y` is represented as:\n",
    "**$$f_{w,b}(x) = wx + b$$**\n",
    " To train a linear regression model, We want to find the best $(w,b)$ parameters that fit our dataset.\n",
    " \n",
    "## Forward Pass\n",
    "The forward method computes the linear regression output for the input data X using the current weights and biases.\n",
    "\n",
    "## Loss (Cost) Function\n",
    "The loss function is used to evaluate the performance of the model. The compute_loss method computes the loss of the linear regression model using the predicted values and actual values. The loss function is given by:\n",
    "\n",
    "$$J(w,b) = \\frac{1}{2m} \\sum_{i=1}^{m}(f_{w,b}(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "where m is the number of training examples, x is the input data, y is the actual output, and w and b are the weights and biases respectively.\n",
    "\n",
    "## Backward Pass\n",
    "The backward method computes the gradients of the weights and biases using the predicted values and actual values. The gradients are used to update the weights and biases during training.\n",
    "\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial b}^{}  = \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1} \\ (f_{w,b}(X^{}) - y^{}) \n",
    "$$\n",
    "$$\n",
    "\\frac{\\partial J(w,b)}{\\partial w}^{}  =  \\frac{1}{m} \\sum\\limits_{i = 0}^{m-1}\\ (f_{w,b}(X^{}) -y^{})X^{} \n",
    "$$\n",
    "\n",
    "## Training\n",
    "The fit method trains the linear regression model for the specified number of iterations using the input data X and actual values y. The method computes the forward pass, computes the cost function, computes the backward pass, and updates the weights and biases. Optionally, it plots the cost function for each iteration. Where updating parameter equations are given by:\n",
    " \n",
    "$$W \\leftarrow W - \\alpha \\frac{\\partial J}{\\partial W}$$\n",
    "$$b \\leftarrow b - \\alpha \\frac{\\partial J}{\\partial b}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ced97f0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T06:33:49.804618Z",
     "iopub.status.busy": "2023-05-14T06:33:49.804184Z",
     "iopub.status.idle": "2023-05-14T06:33:49.822156Z",
     "shell.execute_reply": "2023-05-14T06:33:49.821208Z"
    },
    "papermill": {
     "duration": 0.028078,
     "end_time": "2023-05-14T06:33:49.824633",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.796555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LRwithGradientDecent:\n",
    "    def __init__(self, lr):\n",
    "        self.lr = lr\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.loss_values = []\n",
    "        self.X = None  # Input data\n",
    "        self.y = None  # Actual values\n",
    "        \n",
    "    def initialize_parameters(self):\n",
    "        if self.X.ndim ==1:\n",
    "             self.W = 0\n",
    "        else:\n",
    "            self.W = self.W = np.random.randn(self.X.shape[-1]) * np.sqrt(2 / (self.X.shape[-1] + 1))\n",
    "\n",
    "        self.b = 0\n",
    "        \n",
    "    def forward(self, X):\n",
    "        Z=np.dot(X, self.weights) + self.bias\n",
    "        return Z\n",
    "       \n",
    "    \n",
    "    def compute_loss(self, preds, y):\n",
    "        self.y=y\n",
    "        self.preds=preds\n",
    "\n",
    "        mse_loss = ((preds - y) ** 2).mean()\n",
    "        self.loss_values.append(mse_loss)\n",
    "\n",
    "        return mse_loss\n",
    "    \n",
    "    def backward(self, preds):\n",
    "        d_loss = 2 * (preds - y) / len(preds) \n",
    "\n",
    "       \n",
    "        self.dW = self.X.T.dot(d_loss)  \n",
    "        self.db = d_loss.sum()  \n",
    "\n",
    "    \n",
    "    def update(self,learning_rate):\n",
    "        \n",
    "        self.weights -= learning_rate * self.dW\n",
    "        self.bias -= learning_rate * self.db\n",
    "\n",
    "    def fit(self, X, y, n_iter, plot_cost=True):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.initialize_parameters()\n",
    "        loss_values = []\n",
    "\n",
    "        for _ in range(n_iter):\n",
    "            preds = self.predict(X)\n",
    "            loss = self.compute_loss(preds, y)\n",
    "            self.backward(preds, y)\n",
    "            self.update(learning_rate=0.01)  # Adjust the learning rate as needed\n",
    "\n",
    "            self.loss_values.append(loss)\n",
    "\n",
    "        if plot_cost:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.plot(range(n_iter), self.loss_values)\n",
    "            plt.xlabel(\"Iterations\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            plt.title(\"Cost Function Evolution\")\n",
    "            plt.show()\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "    def predict(self, X):\n",
    "\n",
    "        preds = X.dot(self.weights) + self.bias\n",
    "        return preds\n",
    "\n",
    "model = LRwithGradientDecent(lr=33)\n",
    "\n",
    "\n",
    "model.fit(X,y,n_iter=1000)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f38a153",
   "metadata": {},
   "source": [
    "### Training Linear Regression with Gradient Descent\n",
    "\n",
    "Fit a linear regressor using LRwithGradientDecent class on the training dataset\n",
    "\n",
    "Try a list of lr (at most 0.1) and a list of num_iter values (num_iter=2000 at most) for the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb62437d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-14T06:33:49.839206Z",
     "iopub.status.busy": "2023-05-14T06:33:49.838800Z",
     "iopub.status.idle": "2023-05-14T06:33:50.253829Z",
     "shell.execute_reply": "2023-05-14T06:33:50.252804Z"
    },
    "papermill": {
     "duration": 0.427732,
     "end_time": "2023-05-14T06:33:50.258293",
     "exception": false,
     "start_time": "2023-05-14T06:33:49.830561",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b53cde",
   "metadata": {
    "papermill": {
     "duration": 0.008447,
     "end_time": "2023-05-14T06:33:50.276002",
     "exception": false,
     "start_time": "2023-05-14T06:33:50.267555",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Evaluation\n",
    "\n",
    "Evaluate the model on the training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "461dfa44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47be40d2",
   "metadata": {},
   "source": [
    "### Scikit-learn Linear Regression\n",
    "\n",
    "Train a linear regressor using sklearn library and compare its performance with your LinearRegression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3919eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ede33f7",
   "metadata": {},
   "source": [
    "### Visualization\n",
    "\n",
    "Plot the training data (scatter plot) and the fitted lines by LRwithGradientDecent and LinearRegression (with different colored line plots) in a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37072b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645aa078",
   "metadata": {},
   "source": [
    "\n",
    "Plot the test data (scatter plot) and the fitted lines by LRwithGradientDecent and LinearRegression (with different colored line plots) in a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebbd9957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cd1bc4",
   "metadata": {},
   "source": [
    "## Part 2: Polynomial Regression\n",
    "\n",
    "Fit 2-degree, 4-degree, 8-degree polynomial regression models using only Scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36d45f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly2 = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly3 = PolynomialFeatures(degree=4, include_bias=False)\n",
    "poly4 = PolynomialFeatures(degree=8, include_bias=False)\n",
    "poly_features = poly2.fit_transform(x.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c673fea8",
   "metadata": {},
   "source": [
    "Evaluate the models on the training data and test data and write a comment which is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc1193c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb5dff2",
   "metadata": {},
   "source": [
    "Visualize the test data (scatter plot) and the predictions of three polynomial models (different colored line plots) in a single figure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b35bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da9f432",
   "metadata": {},
   "source": [
    "## Part 3: Regularized Linear Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ee5e3",
   "metadata": {},
   "source": [
    "Read 'data.csv'.\n",
    "\n",
    "Drop the column 'y' from the dataframe to obtain input data X.\n",
    "\n",
    "Get the column 'y' from the dataframe to obtain target data y.\n",
    "\n",
    "Split data (X,y) into training and test datasets with the test ratio of 25% and random_state=0 using Scikit-learn library.\n",
    "\n",
    "Transform the data to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2fb801",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5dbb05",
   "metadata": {},
   "source": [
    "Train a Linear Regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98f043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LRwithGradientDecent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dd856c",
   "metadata": {},
   "source": [
    "Find the classes for linear regression models with L1 and L2 Loss on https://scikit-learn.org/stable/modules/classes.html#module-sklearn.linear_model and import them from sklearn. \n",
    "Please, read the class descriptions to learn class parameters and to accomplish this part correctly.\n",
    "\n",
    "Set the regularization constant for training L1 model to 0.01.\n",
    "\n",
    "Set the regularization constant for training L2 model to 0.7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ccb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6664524a",
   "metadata": {},
   "source": [
    "Import the corresponding function from Scikit-learn library for R-squared metric.\n",
    "\n",
    "Evaluate the performance of three models based on R-squared and comment which is the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7788dd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 14.380051,
   "end_time": "2023-05-14T06:33:51.172747",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-14T06:33:36.792696",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
