# Machine-Learning-and-AI

# IMDB Puan Tahmini Projesi ğŸ¬

* âºï¸ Bu proje, filmlerin Ã§eÅŸitli Ã¶zelliklerini kullanarak IMDB puanlarÄ±nÄ± tahmin etmek iÃ§in makine Ã¶ÄŸrenmesi tekniklerini iÃ§eren bir uygulamadÄ±r. Proje, Python ve popÃ¼ler veri bilimi kÃ¼tÃ¼phaneleri kullanÄ±larak geliÅŸtirilmiÅŸtir.

## Proje Ã–zellikleri â„¹ï¸
AÅŸaÄŸÄ±da, proje kapsamÄ±nda kullanÄ±lan veri setinin sÃ¼tunlarÄ± ve aÃ§Ä±klamalarÄ± bulunmaktadÄ±r:

1. **id**: Her film iÃ§in benzersiz bir kimlik numarasÄ±.
2. **title**: Filmin adÄ±.
3. **vote_average**: KullanÄ±cÄ±lardan alÄ±nan ortalama puan (0 ile 10 arasÄ±nda bir Ã¶lÃ§ekte).
4. **vote_count**: Filmin aldÄ±ÄŸÄ± toplam oy sayÄ±sÄ±.
5. **status**: Filmin mevcut durumu ("YayÄ±nda," "YapÄ±m AÅŸamasÄ±nda" gibi).
6. **release_date**: Filmin resmi olarak yayÄ±nlandÄ±ÄŸÄ± tarih.
7. **revenue**: Filmin elde ettiÄŸi toplam gelir (genellikle USD cinsinden).
8. **runtime**: Filmin sÃ¼resi (dakika cinsinden).
9. **adult**: Filmin yetiÅŸkinlere yÃ¶nelik olup olmadÄ±ÄŸÄ±nÄ± belirten bir ifade ("True" veya "False").
10. **budget**: Filmin yapÄ±m maliyeti (genellikle USD cinsinden).
11. **imdb_id**: IMDb Ã¼zerindeki benzersiz film kimliÄŸi.
12. **original_language**: Filmin orijinal dili (Ã¶rneÄŸin, "en" Ä°ngilizce iÃ§in).
13. **original_title**: Filmin orijinal dilindeki adÄ±.
14. **overview**: Filmin konusuna dair kÄ±sa bir Ã¶zet.
15. **popularity**: Filmin popÃ¼lerliÄŸini gÃ¶steren bir metrik (genellikle gÃ¶rÃ¼ntÃ¼lenme veya arama verileriyle iliÅŸkilidir).
16. **tagline**: Filmle iliÅŸkilendirilen kÄ±sa bir slogan veya ifade.
17. **genres**: Filmin ait olduÄŸu tÃ¼rler (Ã¶rneÄŸin, Aksiyon, Komedi, Drama).
18. **production_companies**: Filmin yapÄ±mÄ±nda yer alan ÅŸirketlerin adlarÄ±.
19. **production_countries**: Filmin yapÄ±ldÄ±ÄŸÄ± Ã¼lkeler.
20. **spoken_languages**: Filmde konuÅŸulan diller.
21. **keywords**: Filmle iliÅŸkilendirilen Ã¶nemli terimler veya kategoriler.

---

## Proje AdÄ±mlarÄ± ğŸªœ
Projenin geliÅŸim sÃ¼reci aÅŸaÄŸÄ±daki adÄ±mlarla gerÃ§ekleÅŸtirilmiÅŸtir:
* Veri seti, bir CSV dosyasÄ±ndan Python ortamÄ±na aktarÄ±lmÄ±ÅŸtÄ±r. Ã–zellikle eksik veya yanlÄ±ÅŸ deÄŸerler kontrol edilmiÅŸtir.
### ğŸ“¥ 1. Dataset'ten Veri Ã‡ekme 
Kod ParÃ§acÄ±ÄŸÄ±:
```python
import pandas as pd

data=pd.read_csv('Kitap1.csv')


```


### ğŸ”¢ 2. Veri Analizi 
* Bu aÅŸamada, verinin yapÄ±sÄ± incelenmiÅŸ ve Ã¶zelliklerin istatistiksel Ã¶zeti elde edilmiÅŸtir. Hangi Ã¶zelliklerin hedef deÄŸiÅŸkeni (vote_average) tahmin etmekte faydalÄ± olabileceÄŸi belirlenmiÅŸ ve gereksiz Ã¶zellikler dataset'ten kaldÄ±rÄ±lmÄ±ÅŸtÄ±r.

Dataset Analizi:
```python
data.head()
data.dtypes
data.info()
data.isnull().sum()
```

Tespit Edilen Gereksiz Ã–zelliklerin KaldÄ±rÄ±lmasÄ±:
```python
data=data.drop(['id','title','keywords','status','original_title','overview','tagline','spoken_languages','imdb_id'],axis=1)
```
![datahead](https://github.com/user-attachments/assets/acd5cd80-3196-4164-905b-e106394e6098)
![datainfo](https://github.com/user-attachments/assets/57296f8e-42fe-46ed-8c06-18b99ce83291)
![dataisnull](https://github.com/user-attachments/assets/c5341ad4-3ced-4c49-8485-a45832838fcb)



### ğŸŒŸ 3. Dataset'in Encoding'e HazÄ±rlanmasÄ± 
* Bu aÅŸamada verilerin geniÅŸ Ã§apta iÅŸlenmesi gerÃ§ekleÅŸtirilmiÅŸtir. Eksik deÄŸerler doldurulmuÅŸtur.

â¡ï¸ 'original_language' Ã¶zelliÄŸi iÃ§in Ã¶rnek uygulama:
```python
#original_language deÄŸiÅŸkeninde toplam sayÄ±sÄ± 12 ten az olan dillerin satÄ±rlarÄ±nÄ± kaldÄ±r
#(12 sayÄ±sÄ± optimum deÄŸer olarak belirlenmiÅŸtir)
language_counts = data['original_language'].value_counts()
languages_to_keep = language_counts[language_counts >= 12].index
data = data[data['original_language'].isin(languages_to_keep)]
```
â¡ï¸ Null DeÄŸerler iÃ§eren SatÄ±rlarÄ±n KaldÄ±rÄ±lmasÄ±:
```python
data = data.dropna(subset=['genres'])
data = data.dropna(subset=['production_companies'])
data = data.dropna(subset=['production_countries'])
```
â¡ï¸ Birden Fazla Strink Value iÃ§eren Ã¶zelliklerin dÃ¼zenlenmesi:
```python
# 'production_countries' sÃ¼tunundaki deÄŸerleri virgÃ¼le gÃ¶re ayÄ±r ve uzunluklarÄ±nÄ± hesapla
data['country_count'] = data['production_countries'].str.split(', ').str.len()

# Ãœlke sayÄ±sÄ± 3'den fazla olan satÄ±rlarÄ± filtre
data = data[data['country_count'] <= 10]

# 'country_count' sÃ¼tununu sil (artÄ±k ihtiyacÄ±mÄ±z yok)
data = data.drop('country_count', axis=1)
```
â¡ï¸ Birden Fazla Strink Value iÃ§eren Ã¶zelliklerin Encoding e hazÄ±rlanmasÄ±:
```python
data['genres_split'] = data['genres'].str.split(', ')
data['production_companies_split'] = data['production_companies'].str.split(', ')
data['production_countries_split'] = data['production_countries'].str.split(', ')
#Ã¶rnek dÃ¶nÃ¼ÅŸÃ¼m formatÄ±: Action,Horror,sc-fi --->[Action,Horror,Sc-fi]
```
â¡ï¸ 'revenue' Ã¶zelliÄŸi iÃ§in 0 iÃ§eren deÄŸerlerin atÄ±lmasÄ±:
```python
zero_revenue_count = data[data['revenue'] == 0]['revenue'].count()
zero_revenue_count
data = data[data['revenue'] != 0]
```
â¡ï¸ 'release_date' Ã¶zelliÄŸinden sadece yÄ±l deÄŸerini Ã§ekme:
```python
# 'release_date' sÃ¼tununu datetime nesnesine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
data['release_date'] = pd.to_datetime(data['release_date'], errors='coerce')

# YÄ±l bilgisini Ã§Ä±karÄ±n ve yeni bir sÃ¼tuna ekle
data['release_year'] = data['release_date'].dt.year

# Sonucu gÃ¶rÃ¼ntÃ¼le
data['release_year']
```
#### ğŸ“Š Encoding Ã–ncesi Grafikler:
1) Verilerin Birbiri ile karÅŸÄ±laÅŸtÄ±rÄ±lmasÄ±
![noktaGrafikleri](https://github.com/user-attachments/assets/84d7b84f-9e97-4a29-92f6-72f5feea013e)
2) Encoding Ã–ncesi Korolasyon:
![encodeOnceKorolasyon](https://github.com/user-attachments/assets/a573ec5b-90ad-41a2-8d90-44a87e6bc980)

### ğŸš€ 4. Dataset'e Encoding uygulanmasÄ±
* Bu aÅŸamada Gerekli Ã¶zellikler (Kategorik veriler) sayÄ±sal formata dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸtÃ¼r ve standardize iÅŸlemleri gerÃ§ekleÅŸtirilmiÅŸtir.
â¡ï¸ 'adult_encoded' Ã¶zelliÄŸi ni booldan int deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rme:
```python
data['adult_encoded'] = data['adult'].astype(int)
data.info()
```
â¡ï¸ 'original_language' Ã¶zelliÄŸini sayÄ±sal ifadeye dÃ¶nÃ¼ÅŸtÃ¼rme (BinarEncoding):
```python
from category_encoders import BinaryEncoder
encoder = BinaryEncoder(cols=['original_language'])
data_encoded = encoder.fit_transform(data)
```
![orginalLanguage](https://github.com/user-attachments/assets/3bda4269-7318-4d46-ada7-f625bd52bf1b)
Birden Fazla Strink Value iÃ§eren Ã¶zellikleri int deÄŸere dÃ¶nÃ¼ÅŸtÃ¼rme (OneHotEncoding):
```python
from sklearn.preprocessing import MultiLabelBinarizer

mlb = MultiLabelBinarizer()
encoded_genres = mlb.fit_transform(data['genres_split'])

# KodlanmÄ±ÅŸ tÃ¼rleri DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼rÃ¼n
encoded_genres_df = pd.DataFrame(encoded_genres, columns=mlb.classes_)

# KodlanmÄ±ÅŸ tÃ¼rleri orijinal DataFrame'e ekleyin
data_encoded = pd.concat([data, encoded_genres_df], axis=1)
```
![turler](https://github.com/user-attachments/assets/8e84d258-27a3-465e-814a-47fcb0efdde6)

â¡ï¸ BÃ¼yÃ¼k deÄŸer iÃ§eren 'revenue' ve 'vote_count' Ã¶zelliklerinin Standardize edilmesi:
```python
# Standardize the 'revenue' ve 'vote_count' variable
scaler = StandardScaler()
data_encoded['revenue'] = scaler.fit_transform(data_encoded[['revenue']])
data_encoded['vote_count'] = scaler.fit_transform(data_encoded[['vote_count']])
```
#### ğŸ“ˆ Encoding SonrasÄ± Grafikler:
1) Encoding SonrasÄ± Korolasyon:
![encodeSonraKorolasyon](https://github.com/user-attachments/assets/eab6b546-c157-4afc-895f-c43042305378)
2) Encoding SonrasÄ± BoxPlot'lar:
![averageBox1](https://github.com/user-attachments/assets/5153139b-ef0b-455c-a635-85a2210d6919)
![popularityBox2](https://github.com/user-attachments/assets/0f0354e7-7741-43c6-8d77-69a6e10c31fc)
![YearBox3](https://github.com/user-attachments/assets/d24757ff-387a-410b-a1fa-cc3d6b44a454)
![RevenueBox4](https://github.com/user-attachments/assets/975f119b-9212-4caa-9d9c-51f26a4eaf6f)


### ğŸ›‘ 5. Model EÄŸitimi ve Model SonuÃ§larÄ±
* Bu aÅŸamada DÃ¶rt farklÄ± model denenmiÅŸ ve en iyi performans Random Forest Regressor ile elde edilmiÅŸtir. Ä°statistiksel metriklerle modeller aÅŸaÄŸÄ±da karÅŸÄ±laÅŸtÄ±rÄ±lmÄ±ÅŸtÄ±r.
ğŸ”¼ Train-Test AyÄ±rma:
```python
# 1. Define features (X) and target (y)
X = data_encoded.drop(['vote_average'], axis=1)
y = data_encoded['vote_average']

# 2. Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
```
â¡ï¸ Random Forest:
```python
model = RandomForestRegressor(n_estimators=100, random_state=42)  # Adjust hyperparameters as needed
model.fit(X_train, y_train)
y_pred = model.predict(X_test)
```
â¡ï¸ Linear Regression:
```python
linear_model = LinearRegression()
linear_model.fit(X_train, y_train)
linear_pred = linear_model.predict(X_test)
```
â¡ï¸ Logistic Regression:
```python
threshold = data_encoded['vote_average'].median()
data_encoded['vote_average_binary'] = (data_encoded['vote_average'] > threshold).astype(int)
X_logreg = data_encoded.drop(['vote_average', 'vote_average_binary'], axis=1)
y_logreg = data_encoded['vote_average_binary']
X_train_logreg, X_test_logreg, y_train_logreg, y_test_logreg = train_test_split(
    X_logreg, y_logreg, test_size=0.33, random_state=42
)
logistic_model = LogisticRegression(max_iter=1000)
logistic_model.fit(X_train_logreg, y_train_logreg)
logistic_pred = logistic_model.predict(X_test_logreg)
```
â¡ï¸ KMeans Regression:
```python
_clusters = 5
kmeans = KMeans(n_clusters=n_clusters, random_state=42)
kmeans.fit(X_train)
train_clusters = kmeans.labels_
kmeans_models = {}
for cluster in range(n_clusters):
    cluster_data_indices = train_clusters == cluster
    X_cluster = X_train[cluster_data_indices]
    y_cluster = y_train[cluster_data_indices]
    model = LinearRegression()
    model.fit(X_cluster, y_cluster)
    kmeans_models[cluster] = model
test_clusters = kmeans.predict(X_test)
kmeans_pred = [kmeans_models[cluster].predict(X_test.iloc[[i]])[0] for i, cluster in enumerate(test_clusters)]
```

### ğŸ’¬ 6. Model SonuÃ§larÄ±nÄ±n KarÅŸÄ±laÅŸtÄ±rÄ±lmasÄ± ve YorumlanmasÄ±

* Model SonuÃ§larÄ±
  ![SonuclarTablo1](https://github.com/user-attachments/assets/e94cc855-62df-459e-8429-119df3c5d875)
  

| Model                 | Ortalama Kare HatasÄ± (MSE) | R-Kare Skoru |
|-----------------------|--------------------------|---------------|
| Random Forest         | En dÃ¼ÅŸÃ¼k               | En yÃ¼ksek    |
| Linear Regression     | Orta                    | Orta          |
| KMeans Regression     | En yÃ¼ksek               | En dÃ¼ÅŸÃ¼k    |
| Logistic Regression   | -                       | -             |

- **Random Forest Regressor** en iyi performansÄ± gÃ¶stermiÅŸtir.
- **Linear Regression** temel bir model olarak iyi bir performans sergilemiÅŸtir.
- **KMeans Regression** bu veri setinde dÃ¼ÅŸÃ¼k bir performans sergilemiÅŸtir.
- **Logistic Regression**, sÄ±nÄ±flandÄ±rma problemleri iÃ§in uygundur ve bu veri setinde deÄŸerlendirilmemiÅŸtir.
  
#### Grafikler:
![DegerlendirmeLine1](https://github.com/user-attachments/assets/8ec24d61-912a-427d-a0f8-bf2dbe96a923)
![DegerlendirmeBar1](https://github.com/user-attachments/assets/4ede1e92-45c9-42ab-a849-b649532460b3)



---

## Projenin AmacÄ± ğŸ—’ï¸
Bu proje, makine Ã¶ÄŸrenmesi algoritmalarÄ±nÄ±n tahmin problemlerindeki gÃ¼cÃ¼nÃ¼ anlamaya yÃ¶nelik bir Ã§alÄ±ÅŸmadÄ±r. Elde edilen sonuÃ§lar, farklÄ± modellerin veri setine uyumunu karÅŸÄ±laÅŸtÄ±rma fÄ±rsatÄ± sunar.

## Gereksinimler ğŸ’¥
- Python 3.8+
- Pandas, NumPy, Scikit-learn

Kurulum:
```bash
pip install -r requirements.txt
```
## TanÄ±tÄ±m Videosu ğŸ“º
https://youtu.be/-BRt86qTgYo
## Sertifikalar ğŸ“„
--> Python EÄŸitimi: [Python_ile_Makine_Ã–ÄŸrenmesi_Sertifika.pdf](https://github.com/user-attachments/files/18470156/Python_ile_Makine_Ogrenmesi_Sertifika.pdf)

